{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ae6d1b",
   "metadata": {},
   "source": [
    "# The aim of the project is to build a fraud detection model using machine learning\n",
    "# This is the second version of the code and was done as an additional code.\n",
    "# This version only uses 1 model and the main point here was to build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading and checking the data\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"creditcard.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43418b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about the data\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35052a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for balance\n",
    "print(data[\"Class\"].value_counts())\n",
    "import seaborn as sns\n",
    "sns.countplot(x = \"Class\", data = data)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Fraud transactions vs non-fraud transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc169c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cant see the significance of time, so im removing\n",
    "data = data.drop([\"Time\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the data\n",
    "x = data.drop([\"Class\"], axis = 1)\n",
    "y = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, random_state= 42, stratify= y)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f2646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#way 2: build a pipeline for preprocessing and training the data \n",
    "numeric_column =[\"Amount\"]\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_transformer = Pipeline(steps = [(\"scaler\", StandardScaler())])\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocess = ColumnTransformer(transformers=[(\"num\", numeric_transformer, \n",
    "                                              numeric_column)])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline(steps = [(\"preprocess\", preprocess), \n",
    "                        (\"classifier\", LogisticRegression(class_weight = \"balanced\", max_iter= 1000))])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "y_proba = clf.predict_proba(x_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bff2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evluate the model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61b7ce",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "# In this version of the fraud detection project,I built a structured pipeline to preprocess the data and train a simple linear regression model.\n",
    "# A ColumnTransformer was used to apply preprocessing only to the Amount feature\n",
    "# The model used was Logistic Regression with balanced class weights to handle the class imbalance in the dataset\n",
    "# The pipeline showed a strong performance in detecting fraud\n",
    "# Approximately 74% of fraudulent transactions were correctly identified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
